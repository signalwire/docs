---
title: Managing Long Context Windows
slug: /ai/get-started/prompt-engineering/advanced-techniques/managing-long-context
description: Optimize prompts for long-running conversations and handle large context windows effectively in real-time applications.
draft: true
---

import Admonition from '@theme/Admonition';

# Managing Long Context Windows

<Subtitle>Optimize prompts for long-running conversations in real-time applications</Subtitle>

## Understanding the Challenge

Real-time conversational AI presents unique challenges with context management, particularly for SignalWire voice and video applications where conversations can be extended and the entire conversation transcript is passed with each turn. This guide addresses strategies for effectively managing long-running conversations with SignalWire AI Agents.

### What Are Long Context Windows?

The context window refers to the amount of information (measured in tokens) that an AI model can process at once. This includes both the prompt and the conversation history. For SignalWire AI Agents, this context includes:

- The primary prompt (instructions to the AI)
- The entire conversation history
- Any additional context provided through functions or system messages

As conversations progress, this context grows continuously, which can lead to several challenges:

1. **Performance Degradation**: Processing large contexts can slow response times
2. **Information Overload**: Important information may get buried in lengthy contexts
3. **Context Window Limitations**: Models have maximum token limits
4. **Recency Bias**: Many models give higher weight to more recent information
5. **Memory Constraints**: Earlier parts of conversations may be ignored or forgotten

## Strategies for Context Management

### Context Window Optimization

When designing prompts for long-running conversations, consider these techniques to optimize context window usage:

#### Prioritize Recent and Critical Information

Structure your prompts to emphasize critical information where the model is most likely to focus:

```markdown
# Prioritization Techniques

## Important Information Placement
- Place critical instructions at the end of your prompts where possible
- SignalWire's 4o-mini tends to focus more attention on the most recent context
- Repeat essential guidelines periodically throughout long interactions

## Memory Reinforcement
- Periodically restate key constraints or requirements
- Include important parameters in follow-up questions
- Repeat customer-specific details when they become relevant again
```

#### Implement Conversation Summarization

Rather than keeping the entire verbatim conversation history, implement summarization techniques:

```markdown
# Summarization Approach

## Progressive Summarization
- After key conversation segments, generate a summary of important points
- Replace detailed conversation with condensed summaries
- Maintain a "running summary" of the conversation that updates with each turn

## Information Categorization
- Organize extracted information into categories (e.g., customer details, requirements, decisions)
- Prioritize factual information over conversational elements
- Create a structured knowledge representation that's more token-efficient
```

<Admonition type="tip">
For voice applications, summarization is especially important since spoken conversations can quickly consume large portions of the context window. Consider implementing automatic summarization after predefined turn counts.
</Admonition>

#### Context Pruning Strategies

Implement selective removal of conversational content that's no longer needed:

```markdown
# Context Pruning Guidelines

## Selective Retention
- Discard resolved queries and their associated contexts
- Remove standard greetings, acknowledgments, and pleasantries
- Keep only the most recent instances of repetitive questions

## Topic-Based Pruning
- When topics change, summarize and prune previous topic details
- Retain only conclusions and decisions from previous topics
- Keep cross-topic references when there are dependencies
```

### Technical Implementation Approaches

#### Memory Management Architectures

Consider these architecture patterns for managing long-running conversations:

```markdown
# Memory Management Patterns

## Vector Database Retrieval
- Store conversation segments in a vector database
- Retrieve only the most relevant context based on current query
- Append retrieved context to current prompt when needed

## Hierarchical Memory
- Maintain multiple memory tiers:
  * Working memory (most recent exchanges)
  * Short-term memory (current topic details)
  * Long-term memory (important facts, customer information)
- Selectively pull information from each tier based on relevance

## External State Management
- Store structured data extracted from conversation externally
- Pass only the structured state and recent messages to the model
- Reconstruct context as needed based on conversation direction
```

#### Streaming and Progressive Responses

For performance optimization in real-time contexts:

```markdown
# Real-Time Optimization Techniques

## Streaming Implementation
- Use streaming responses to begin generating output while processing context
- This maintains conversational flow even with complex contexts
- Particularly important for voice where pauses are more noticeable

## Progressive Loading
- Load context in stages, starting with most critical elements
- Add additional context only if initial response appears insufficient
- Implement "continue thinking" mechanisms for complex topics
```

#### Specialized Agents with Focused Contexts

Consider using multiple specialized agents instead of a single agent with massive context:

```markdown
# Multi-Agent Architecture

## Agent Specialization
- Use different agents for different conversation phases or topics
- Each agent receives only relevant context for its specialty
- Implement agent coordination through a central orchestrator

## Context Transfer Protocol
- Define how context is summarized and handed off between agents
- Include critical customer information in all handoffs
- Provide conversation summaries during transitions
```

## SignalWire-Specific Implementation

### Voice Applications

Voice interactions have specific considerations for context management:

```markdown
# Voice Context Management

## Temporal Considerations
- Voice conversations move more slowly than text, but context accumulates just as quickly
- Consider time-based summarization (e.g., summarize after 5 minutes)
- Implement context decay where older information gradually receives less weight

## Speech-Specific Optimizations
- Filter out filler words and hesitations from transcripts
- Identify and compact repetitive speech patterns
- Preserve emotional signals and emphasis indicators in summaries

## Turn Management
- Define clear turn boundaries in the context
- Implement "continuation markers" for when user speech is separated into multiple turns
- Merge closely timed consecutive turns from the same speaker
```

### Video Applications

Video interactions have multimodal context considerations:

```markdown
# Video Context Management

## Visual Context
- Include references to shared visual context in conversation summaries
- Summarize visual actions or information shared on screen
- Maintain a record of visual state changes (screen sharing, document sharing)

## Attention Management
- Note when users direct attention to specific visual elements
- Maintain context about UI states and visible options
- Track focus shifts between verbal and visual channels
```

### Implementation Patterns for SignalWire AI Agents

Here are practical patterns you can implement in your SignalWire AI Agents:

#### Conversation State Tracking

```javascript
// Example: Tracking conversation state for context management
let conversationState = {
  userProfile: {
    name: null,
    accountType: null,
    preferences: {}
  },
  currentTopic: null,
  resolvedTopics: [],
  importantFacts: [],
  conversationSummary: "",
  turnCount: 0
};

// Update state with each turn
function updateConversationState(userMessage, aiResponse) {
  conversationState.turnCount++;
  
  // Extract and update user information
  const extractedInfo = extractUserInfo(userMessage);
  conversationState.userProfile = {...conversationState.userProfile, ...extractedInfo};
  
  // Update topic tracking
  const newTopic = identifyTopic(userMessage);
  if (newTopic !== conversationState.currentTopic) {
    if (conversationState.currentTopic) {
      conversationState.resolvedTopics.push(conversationState.currentTopic);
    }
    conversationState.currentTopic = newTopic;
  }
  
  // Periodically summarize conversation
  if (conversationState.turnCount % 5 === 0) {
    conversationState.conversationSummary = summarizeConversation(
      conversationState.conversationSummary,
      userMessage,
      aiResponse
    );
  }
  
  // Extract important facts
  const newFacts = extractImportantFacts(userMessage, aiResponse);
  conversationState.importantFacts = [...conversationState.importantFacts, ...newFacts];
}

// Generate optimized context for the next turn
function generateOptimizedContext() {
  return {
    userProfile: conversationState.userProfile,
    currentTopic: conversationState.currentTopic,
    conversationSummary: conversationState.conversationSummary,
    relevantFacts: getRelevantFacts(conversationState.currentTopic),
    recentTurns: getRecentConversationTurns(3) // Only include last 3 turns verbatim
  };
}
```

#### Dynamic Prompt Management

```javascript
// Example: Dynamic prompt construction based on context length
function constructOptimizedPrompt(basePrompt, conversationHistory) {
  const estimatedTokens = estimateTokenCount(basePrompt + conversationHistory);
  
  if (estimatedTokens < 2000) {
    // Context is small enough to include everything
    return basePrompt + "\n\nConversation History:\n" + conversationHistory;
  } else if (estimatedTokens < 4000) {
    // Medium context - summarize older turns
    const recentTurns = extractRecentTurns(conversationHistory, 5);
    const summarizedHistory = summarizeOlderTurns(conversationHistory);
    return basePrompt + "\n\nConversation Summary:\n" + summarizedHistory + "\n\nRecent Interactions:\n" + recentTurns;
  } else {
    // Large context - use highly summarized context + very recent turns
    const recentTurns = extractRecentTurns(conversationHistory, 3);
    const topicSummaries = summarizeByTopic(conversationHistory);
    const keyFacts = extractKeyFacts(conversationHistory);
    
    return basePrompt + 
           "\n\nKey Customer Information:\n" + keyFacts +
           "\n\nTopics Discussed:\n" + topicSummaries +
           "\n\nMost Recent Interactions:\n" + recentTurns;
  }
}
```

## Best Practices for Long-Running Conversations

### Do's and Don'ts

#### Do

- **Implement periodic summarization**: Regularly condense earlier parts of conversation
- **Prioritize recency**: Structure prompts with most important information towards the end
- **Track key information externally**: Maintain critical data outside the context window
- **Test context strategies**: Measure performance with different context management approaches
- **Include conversation metadata**: Track turn counts, time elapsed, and topic shifts

#### Don't

- **Rely on raw conversation history alone**: Unprocessed history is inefficient
- **Assume consistent recall**: Don't expect the model to reliably reference far-back information
- **Overload with redundant information**: Eliminate duplicative context
- **Ignore model-specific biases**: Different models handle long contexts differently
- **Sacrifice critical information**: Don't prune regulatory or compliance-related details

### Pattern Examples

#### Tiered Context Structure

Organize your prompt context in tiers based on importance and recency:

```markdown
# Tiered Context Structure

## Critical Information (Always Included)
- Customer identity and account details
- Current topic or query being addressed
- Specific constraints or requirements for the current topic

## Recent Context (Usually Included)
- Last 3-5 conversation turns in full
- Any decisions or choices made in the current topic
- Errors or misunderstandings that have occurred recently

## Summarized Context (Included as Space Permits)
- Topic summaries from earlier in the conversation
- Notable choices or preferences expressed previously
- General patterns of interaction

## Background Information (Selectively Included)
- Product knowledge relevant to current topic
- Previous interaction history summaries
- General user preferences established in past interactions
```

#### Prompt Refresh Technique

For extremely long conversations, consider implementing a prompt refresh strategy:

```markdown
# Prompt Refresh Strategy

Every 15-20 conversation turns:

1. Generate a comprehensive conversation summary
2. Extract key customer information and preferences
3. Identify unresolved items or pending actions
4. Construct a fresh prompt with this distilled information
5. Explicitly acknowledge the reset to the customer:
   "Let me make sure I have all your information correct so far..."
6. Continue with the refreshed context
```

<Admonition type="important">
When implementing context management strategies for regulated industries (healthcare, finance, etc.), ensure your summarization and pruning logic preserves all information required for compliance and record-keeping purposes.
</Admonition>

## Practical Examples

### Example 1: Customer Support Conversation

Here's how you might structure context management for a long-running customer support interaction:

```markdown
# Customer Support Context Management

## Base Prompt (Always Present)
You are a helpful SignalWire Support Agent. You help customers troubleshoot technical issues with SignalWire's Voice, Video, and Messaging APIs. Maintain a friendly, professional tone and focus on resolving the customer's issue efficiently.

## Customer Information
Name: ${customer.name}
Account Type: ${customer.accountType}
Current Plan: ${customer.plan}
Support Entitlement: ${customer.supportLevel}

## Current Ticket Information
Ticket ID: ${ticket.id}
Issue Category: ${ticket.category}
Priority: ${ticket.priority}
Time Open: ${ticket.timeOpen}

## Conversation Summary
${generateConversationSummary()}

## Key Facts Established
${extractKeyFacts()}

## Current Troubleshooting Status
Current Theory: ${troubleshooting.currentTheory}
Confirmed Factors: ${troubleshooting.confirmedFactors}
Eliminated Possibilities: ${troubleshooting.eliminatedOptions}
Pending Verification: ${troubleshooting.pendingChecks}

## Recent Conversation (Last 3 Turns)
${getRecentConversationTurns(3)}
```

### Example 2: Sales Consultation Context

Here's a context management approach for a sales conversation:

```markdown
# Sales Consultation Context Management

## Base Prompt
You are a SignalWire Solution Consultant helping potential customers understand SignalWire's communication APIs and services. Your goal is to understand their requirements and recommend appropriate SignalWire products and services.

## Customer Profile
Company: ${prospect.companyName}
Industry: ${prospect.industry}
Size: ${prospect.companySize}
Current Communications: ${prospect.currentSolution}

## Established Requirements
Must-Have Features: ${requirements.mustHave}
Nice-to-Have Features: ${requirements.niceToHave}
Deal Breakers: ${requirements.dealBreakers}
Budget Constraints: ${requirements.budget}

## Conversation Progress
Qualification: ${progress.qualification}%
Needs Analysis: ${progress.needsAnalysis}%
Solution Presentation: ${progress.solutionPresentation}%
Objection Handling: ${progress.objectionHandling}%

## Recommended Solutions
Primary Recommendation: ${recommendations.primary}
Alternatives Discussed: ${recommendations.alternatives}
Custom Requirements: ${recommendations.customNeeds}

## Action Items
${actionItems.map(item => `- ${item}`).join('\n')}

## Conversation Summary
${generateConversationSummary()}

## Recent Conversation (Last 3 Turns)
${getRecentConversationTurns(3)}
```

## Tools and Techniques for Implementation

### Conversation Summarization Approaches

Implement effective summarization with these techniques:

#### Topic-Based Summaries

```javascript
function generateTopicBasedSummary(conversationHistory) {
  // Identify distinct topics in the conversation
  const topics = identifyConversationTopics(conversationHistory);
  
  let summaries = [];
  for (const topic of topics) {
    // Extract turns related to this topic
    const topicTurns = extractTurnsByTopic(conversationHistory, topic);
    
    // Generate a concise summary of this topic
    const topicSummary = summarizeTopic(topic, topicTurns);
    
    summaries.push(`Topic: ${topic}\nSummary: ${topicSummary}`);
  }
  
  return summaries.join('\n\n');
}
```

#### Incremental Summarization

```javascript
// Keep a running summary that updates with each turn
let conversationSummary = "";

function updateIncrementalSummary(userMessage, aiResponse) {
  // Determine if this exchange contains new significant information
  if (containsSignificantInformation(userMessage, aiResponse)) {
    // Extract the key information from this exchange
    const newInformation = extractKeyInformation(userMessage, aiResponse);
    
    // Update the running summary with this new information
    conversationSummary = updateSummaryWithNewInfo(conversationSummary, newInformation);
  }
  
  return conversationSummary;
}
```

### External Memory Solutions

Consider these approaches for maintaining information outside the context window:

#### Vector Store Integration

```javascript
// Using a vector database to store and retrieve conversation segments
const { OpenAIEmbeddings } = require('langchain/embeddings/openai');
const { Chroma } = require('langchain/vectorstores/chroma');

// Initialize vector store
const embeddings = new OpenAIEmbeddings();
const vectorStore = await Chroma.fromExistingCollection(embeddings, { collectionName: "conversation_memory" });

// Store conversation turns
async function storeConversationTurn(turnId, speaker, message) {
  const embedding = await embeddings.embedQuery(message);
  await vectorStore.addDocuments([{
    pageContent: message,
    metadata: { turnId, speaker, timestamp: Date.now() }
  }]);
}

// Retrieve relevant context
async function retrieveRelevantContext(currentUserMessage) {
  const results = await vectorStore.similaritySearch(currentUserMessage, 5);
  return results.map(item => `${item.metadata.speaker}: ${item.pageContent}`).join('\n');
}
```

#### Session State Management

```javascript
// Maintain structured conversation state
class ConversationStateManager {
  constructor() {
    this.state = {
      userInfo: {},
      preferences: {},
      confirmedFacts: [],
      decisions: {},
      currentTopic: null,
      topicHistory: [],
      turnCount: 0
    };
  }
  
  updateUserInfo(newInfo) {
    this.state.userInfo = {...this.state.userInfo, ...newInfo};
  }
  
  addConfirmedFact(fact) {
    if (!this.state.confirmedFacts.includes(fact)) {
      this.state.confirmedFacts.push(fact);
    }
  }
  
  setTopic(topic) {
    if (this.state.currentTopic && this.state.currentTopic !== topic) {
      this.state.topicHistory.push(this.state.currentTopic);
    }
    this.state.currentTopic = topic;
  }
  
  recordDecision(topic, decision) {
    this.state.decisions[topic] = decision;
  }
  
  incrementTurn() {
    this.state.turnCount++;
  }
  
  // Generate context from state
  generateContext() {
    let context = [];
    
    // Always include user info
    context.push(`User Information: ${JSON.stringify(this.state.userInfo)}`);
    
    // Include current topic
    context.push(`Current Topic: ${this.state.currentTopic}`);
    
    // Include relevant confirmed facts (filter by current topic if needed)
    const relevantFacts = this.getRelevantFacts(this.state.currentTopic);
    context.push(`Relevant Facts: ${relevantFacts.join(', ')}`);
    
    // Include relevant decisions
    context.push(`Previous Decisions: ${JSON.stringify(this.getRelevantDecisions())}`);
    
    return context.join('\n');
  }
  
  getRelevantFacts(topic) {
    // Logic to filter facts by relevance to current topic
    return this.state.confirmedFacts.filter(fact => isRelevantToTopic(fact, topic));
  }
  
  getRelevantDecisions() {
    // Logic to select relevant past decisions
    const relevantDecisions = {};
    const relevantTopics = getRelatedTopics(this.state.currentTopic);
    
    for (const topic of relevantTopics) {
      if (this.state.decisions[topic]) {
        relevantDecisions[topic] = this.state.decisions[topic];
      }
    }
    
    return relevantDecisions;
  }
}
```

## Next Steps

Now that you understand how to manage long context windows, you can:

- Implement these strategies alongside [Multishot Prompting](/ai/get-started/prompt-engineering/advanced-techniques/multishot-prompting)
- Combine with the [RISEN Framework](/ai/get-started/prompt-engineering/advanced-techniques/risen-framework) for structured interactions
- Enhance your implementations with [Chain of Thought](/ai/get-started/prompt-engineering/advanced-techniques/chain-of-thought) reasoning

Return to the [Advanced Techniques](/ai/get-started/prompt-engineering/advanced-techniques) overview to explore more sophisticated prompt engineering approaches. 