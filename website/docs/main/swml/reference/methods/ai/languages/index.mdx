---
unlisted: false
sidebar_label: ai.languages
hide_title: false
sidebar_position: 1
slug: /swml/methods/ai/languages
title: ai.languages
description: Configure the spoken language of your AI Agent, as well as the TTS engine, voice, and fillers.
tags: ['swml']
---

import APIField from "@site/src/components/APIField";

[tts-providers]: /voice/getting-started/voice-and-languages#providers
[voices-and-languages]: /voice/getting-started/voice-and-languages
[swaig-functions]: /swml/methods/ai/swaig/functions
[deepgram-codes]: https://developers.deepgram.com/docs/models-languages-overview#nova-3
[ai-params]: /swml/methods/ai/params

# ai.languages

Use `ai.languages` to configure the spoken language of your AI Agent, as well as the TTS engine, voice, and fillers.

<APIField
  name="ai.languages"
  type="object[]"
>
  An array of objects that accepts the [`languages parameters`](#languages-parameters).
</APIField>

##  Parameters {#languages-parameters}

<APIField
  name="languages[].name"
  type="string"
  required={true}
>
  Name of the language ("French", "English", etc). This value is used in the system prompt to instruct the LLM what language is being spoken.
</APIField>

<APIField
  name="languages[].code"
  type="string"
  required={true}
>
  Set the language code for <Tooltips tip="Automatic Speech Recognition">ASR</Tooltips> (<Tooltips tip="Speech-to-text">STT</Tooltips>) purposes. 
  By default, SignalWire uses Deepgram's Nova-3 STT engine, so this value should match a code from Deepgram's [Nova-3 language codes table][deepgram-codes].
  
  **Note:** If a different STT model was selected using the [`openai_asr_engine` parameter](/swml/methods/ai/params), you must select a code supported by that engine.
</APIField>

<APIField
  name="languages[].voice"
  type="string"
  required={true}
>
  String format: `<engine id>.<voice id>`.<br/>Select engine from `gcloud`, `polly`, `elevenlabs`, or `deepgram`. Select voice from [TTS provider reference][tts-providers].<br/>For example, `"gcloud.fr-FR-Neural2-B"`.

  See [`voice` usage](#use-voice-strings) for more details.
</APIField>

<APIField
  name="languages[].emotion"
  type="string"
  default="None"
>
  Enables emotion for the set TTS engine. This allows the AI to express emotions when speaking. A global emotion or specific emotions for certain topics can be set within the prompt of the AI.<br />*Valid values:* `auto`<br />**IMPORTANT:** Only works with `Cartesia` TTS engine.
</APIField>

<APIField
  name="languages[].function_fillers"
  type="string[]"
  default="None"
>
  An array of strings to be used as fillers in the conversation when the agent is calling a [`SWAIG function`][swaig-functions]. The filler is played asynchronously during the function call.
</APIField>

<APIField
  name="languages[].model"
  type="string"
  default="None"
>
  The model to use for the specified TTS engine (e.g. `arcana`). Check the [TTS provider reference][tts-providers] for the available models.
</APIField>

<APIField
  name="languages[].speech_fillers"
  type="string[]"
  default="None"
>
  An array of strings to be used as fillers in the conversation. This helps the AI break silence between responses.
  
  **Note:** `speech_fillers` are used between every 'turn' taken by the LLM, including at the beginning of the call. For more targed fillers, consider using `function_fillers`.
</APIField>

<APIField
  name="languages[].speed"
  type="string"
  default="None"
>
  The speed to use for the specified TTS engine. This allows the AI to speak at a different speed at different points in the conversation. The speed behavior can be defined in the prompt of the AI.<br />*Valid values:** `auto`<br />**IMPORTANT:** Only works with [`Cartesia`](/voice/tts/cartesia) TTS engine.
</APIField>

<APIField
  name="languages[].params"
  type="object"
  default="None"
>
  TTS engine-specific parameters for this language. 
  Accepts the [`languages.params` parameters](/swml/methods/ai/languages/params).
</APIField>

<APIField
  name="languages[].fillers"
  type="string[]"
  deprecated={true}
  default="None"
>
  <span className="deprecated-arg">An array of strings to be used as fillers in the conversation and when the agent is calling a [`SWAIG function`][swaig-functions].</span><span className="deprecated-desc">**Deprecated**: Use `speech_fillers` and `function_fillers` instead.</span>
</APIField>

<APIField
  name="languages[].engine"
  type="string"
  deprecated={true}
  default="`gcloud`"
>
  <span className="deprecated-arg">The engine to use for the language. For example, `"elevenlabs"`.</span><span className="deprecated-desc">**Deprecated.** Set the engine with the [`voice`](#use-voice-strings) parameter.</span>
</APIField>

---

### Use `voice` strings

Compose the `voice` string using the `<engine id>.<voice id>` syntax.

First, select your engine using the `gcloud`, `polly`, `elevenlabs`, or `deepgram` identifier. 
Append a period (`.`), and then the specific voice ID (for example, `en-US-Casual-K`) from the TTS provider. 
Refer to SignalWire's [Supported Voices and Languages][tts-providers]
for guides on configuring voice ID strings for each provider.

## **Supported voices and languages**

SignalWire's cloud platform integrates with leading text-to-speech providers.
For a comprehensive list of supported engines, languages, and voices, refer to our documentation on 
[Supported Voices and Languages][voices-and-languages].

## **Examples**

### Set a single language

SWML will automatically assign the language (and other required parameters) to the defaults in the above table if left unset.
This example uses `ai.language` to configure a specific English-speaking voice from ElevenLabs.

```yaml andJson
languages:
  - name: English
    code: en-US
    voice: elevenlabs.rachel
    speech_fillers:
      - one moment please,
      - hmm...
      - let's see,
```

### Set multiple languages

SWML will automatically assign the language (and other required parameters) to the defaults in the above table if left unset.
This example uses `ai.language` to configure multiple languages using different TTS engines.

```yaml andJson
languages:
  - name: Mandarin
    code: cmn-TW
    voice: gcloud.cmn-TW-Standard-A
  - name: English
    code: en-US
    voice: elevenlabs.rachel
```

### Configure global ElevenLabs parameters

Configure stability and similarity globally for all ElevenLabs voices using `ai.params`:

```yaml andJson
ai:
  params:
    eleven_labs_stability: 0.6
    eleven_labs_similarity: 0.8
  languages:
    - name: English
      code: en-US
      voice: elevenlabs.josh
```

### Configure per-language ElevenLabs parameters

Configure different stability and similarity values for each language using `languages[].params`:

```yaml andJson
ai:
  languages:
    - name: English
      code: en-US
      voice: elevenlabs.josh
      params:
        stability: 0.6
        similarity: 0.8
    - name: Spanish
      code: es-ES
      voice: elevenlabs.maria
      params:
        stability: 0.4
        similarity: 0.9
```

### Mixed configuration

Per-language params override global params:

```yaml andJson
ai:
  params:
    eleven_labs_stability: 0.5
    eleven_labs_similarity: 0.75
  languages:
    - name: English
      code: en-US
      voice: elevenlabs.josh
      # Uses global defaults: stability=0.5, similarity=0.75
    - name: Spanish
      code: es-ES
      voice: elevenlabs.maria
      params:
        stability: 0.3
        # Overrides only stability, similarity still uses global 0.75
```

{/*

This example commented out as the language-switching behavior is a bit inconsistent.

### Full SWML script

The following example is valid SWML which you can copy and paste into a new 
[SWML Script in your SignalWire Space](https://my.signalwire.com?page=relay-bins) 
for testing purposes.

The script includes the minimum required initialization statements, and initializes the 
[ai](../ai/index.mdx)
method with a simple prompt informing the AI Agent of its four available languages.

```yaml andJson
version: 1.0.0
sections:
  main:
   - ai:
       prompt:
         text: |
           You can speak American English, Australian English, Iberian Spanish, and Mandarin Chinese.
           You're a polyglot and enjoy speaking in different languages.
           Switch languages freely whenever the user switches languages.
       languages:
         - name: American English
           code: en-US
           voice: elevenlabs.giovanni
           engine: elevenlabs
         - name: Iberian Spanish
           code: es-ES
           voice: elevenlabs.freya
           engine: elevenlabs
         - name: Australian English
           code: en-AU
           voice: gcloud.en-AU-Neural2-A
           engine: gcloud
         - name: Mandarin Chinese
           code: cmn-TW
           voice: gcloud.cmn-TW-Standard-A
           engine: gcloud
```

*/}
