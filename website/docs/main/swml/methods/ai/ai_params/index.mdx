---
unlisted: false
sidebar_label: ai.params
hide_title: false
sidebar_position: 0
title: ai.params
slug: /swml/methods/ai/params
description: Parameters for AI that can customize the AI agent's behavior.
tags: ['swml']
---

import AvailableAI from './_available_ai_models.mdx'
import APIField from "@site/src/components/APIField";

[functions-fillers]: /swml/methods/ai/swaig/functions/fillers
[conscience]: ./conscience.mdx
[hold-music]: ./hold_music.mdx
[interrupt-prompt]: ./interrupt_prompt.mdx
[ai-languages]: ../ai_languages.mdx
[ai-params]: ./index.mdx
[get-visual-input]: /swml/methods/ai/swaig/internal_fillers#internal_fillers-parameters
[tone-stream]: https://developer.signalwire.com/freeswitch/FreeSWITCH-Explained/Modules/mod-dptools/mod-dptools:-gentones/Tone_stream_6586599/
[iana-tz]: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones

Parameters for AI that can be passed in `ai.params` at the top level of the [`ai` Method][ai-params].
These parameters control the fundamental behavior and capabilities of the AI agent, including model selection, conversation management, and advanced features like thinking and vision.


<APIField
  name="params"
  type="object"
>
  An object that accepts the [`params parameters`](#params-parameters).
</APIField>



## params Parameters


<APIField
  name="ai_model"
  type="string"
  default="gpt-4o-mini"
>
  The AI model that the AI Agent will use during the conversation.<br /><AvailableAI />
</APIField>

<APIField
  name="conscience"
  type="string"
  default='"Remember to stay in character. You must not do anything outside the scope of your provided role."'
>
  Sets the prompt which binds the agent to its purpose.
</APIField>

<APIField
  name="conversation_id"
  type="string"
>
  Used by `check_for_input` and `save_conversation` to identify an individual conversation.
</APIField>

<APIField
  name="conversation_sliding_window"
  type="integer"
>
  Sets the conversation history window size (number of turns to keep in context).
</APIField>

<APIField
  name="direction"
  type="string"
  default="the natural direction of the call"
>
  Forces the direction of the call to the assistant. Valid values are `inbound` and `outbound`.
</APIField>

<APIField
  name="enable_thinking"
  type="boolean"
  default="false"
>
  Enables thinking output for the AI Agent. When set to `true`, the AI Agent will be able to utilize thinking capabilities.<br />**Important**: This may introduce a little bit of latency as the AI will use an additional turn in the conversation to think about the query.
</APIField>

<APIField
  name="enable_vision"
  type="boolean"
  default="false"
>
  Enables visual input processing for the AI Agent. The image that will be used for visual processing will be gathered from the users camera if video is available on the call.<br/>When set to `true`, the AI Agent will be able to utilize visual processing capabilities, while leveraging the [`get_visual_input`][get-visual-input] function.
</APIField>

<APIField
  name="languages_enabled"
  type="boolean"
  default="false"
>
  Allows multilingualism when `true`.
</APIField>

<APIField
  name="local_tz"
  type="string"
  default="GMT"
>
  The local timezone setting for the AI. Value should use [IANA TZ ID][iana-tz]
</APIField>

<APIField
  name="save_conversation"
  type="boolean"
  default="false"
>
  Send a summary of the conversation after the call ends. This requires a `post_url` to be set in the [`ai parameters`][ai-params] and the `conversation_id` defined below. This eliminates the need for a `post_prompt` in the `ai` parameters.
</APIField>

<APIField
  name="summary_mode"
  type="string"
>
  Summary generation mode. Valid values: `"string"`, `"original"`.
</APIField>

<APIField
  name="thinking_model"
  type="string"
  default="Value of ai_model parameter"
>
  The AI model that the AI Agent will use when utilizing thinking capabilities.<br /><AvailableAI />
</APIField>

<APIField
  name="transfer_summary"
  type="boolean"
  default="false"
>
  Pass a summary of a conversation from one AI agent to another. For example, transfer a call summary between support agents in two departments.
</APIField>

<APIField
  name="vision_model"
  type="string"
  default="Value of ai_model parameter"
>
  The AI model that the AI Agent will use when utilizing vision capabilities.<br /><AvailableAI />
</APIField>

<APIField
  name="wait_for_user"
  type="boolean"
  default="false"
>
  When false, AI agent will initialize dialogue after call is setup. When true, agent will wait for the user to speak first.
</APIField>

### Speech Recognition

Configure how the AI agent processes and understands spoken input, including speaker identification, voice activity detection, and transcription settings.

<APIField
  name="asr_diarize"
  type="boolean"
  default="false"
>
  If true, enables speaker diarization in ASR (Automatic Speech Recognition). This will break up the transcript into chunks, with each chunk containing a unique identity (e.g speaker1, speaker2, etc.) and the text they spoke.
</APIField>

<APIField
  name="asr_smart_format"
  type="boolean"
  default="false"
>
  Enables smart formatting for ASR output, improving the readability of transcribed text.
</APIField>

<APIField
  name="asr_speaker_affinity"
  type="boolean"
  default="false"
>
  If true, will force the AI Agent to only respond to the speaker who responds to the AI Agent first. Any other speaker will be ignored.
</APIField>

<APIField
  name="end_of_speech_timeout"
  type="integer"
  default="700"
>
  Amount of silence, in ms, at the end of an utterance to detect end of speech. Allowed values from `0`-`10,000`.
</APIField>

<APIField
  name="energy_level"
  type="number"
  default="52"
>
  Amount of energy necessary for bot to hear you (in dB). Allowed values from `0.0`-`100.0`.
</APIField>

<APIField
  name="first_word_timeout"
  type="integer"
  default="1000"
>
  Timeout for detecting the first word of user speech. Allowed values from `0`-`10,000` ms.
</APIField>

<APIField
  name="llm_diarize_aware"
  type="boolean"
  default="false"
>
  If true, the AI Agent will be involved with the diarization process. Users can state who they are at the start of the conversation and the AI Agent will be able to correctly identify them when they are speaking later in the conversation.
</APIField>

<APIField
  name="openai_asr_engine"
  type="string"
  default="deepgram:nova-3"
>
  The ASR (Automatic Speech Recognition) engine to use. Common values include `deepgram:nova-2`, `deepgram:nova-3`, and other supported ASR engines.
</APIField>

### Speech Synthesis

Customize the AI agent's voice output, including volume control, voice characteristics, emotional range, and video avatars for visual interactions.

<APIField
  name="ai_volume"
  type="integer"
  default="0"
>
  Adjust the volume of the AI. Allowed values from `-50`-`50`.
</APIField>

<APIField
  name="eleven_labs_similarity"
  type="number"
>
  The similarity slider dictates how closely the AI should adhere to the original voice when attempting to replicate it. The higher the similarity, the closer the AI will sound to the original voice. Valid values range from `0.01` to `1.0`.<br /><br />**Important**: This will only works when `elevenlabs` is set in the [`ai.languages.voice`][ai-languages] as the engine id.
</APIField>

<APIField
  name="eleven_labs_stability"
  type="number"
>
  The stability slider determines how stable the voice is and the randomness between each generation. Lowering this slider introduces a broader emotional range for the voice. Valid values range from `0.01` to `1.0`.<br /><br />**Important**: This will only works when `elevenlabs` is set in the [`ai.languages.voice`][ai-languages] as the engine id.
</APIField>

<APIField
  name="max_emotion"
  type="integer"
  default="30"
>
  Maximum emotion intensity for text-to-speech. Allowed values from `1`-`30`.
</APIField>

<APIField
  name="speech_gen_quick_stops"
  type="integer"
  default="3"
>
  Number of quick stops for speech generation. Allowed values from `0`-`10`.
</APIField>

<APIField
  name="tts_number_format"
  type="string"
  default="international"
>
  The format of the number the AI will reference the phone number.<br />**Valid Values**: `international`(e.g. **+12345678901**) or `national`(e.g. **(234) 567-8901**).
</APIField>

<APIField
  name="video_idle_file"
  type="string"
>
  URL of a video file to play when AI is idle. Only works for calls that support video.
</APIField>

<APIField
  name="video_listening_file"
  type="string"
>
  URL of a video file to play when AI is listening to the user speak. Only works for calls that support video.
</APIField>

<APIField
  name="video_talking_file"
  type="string"
>
  URL of a video file to play when AI is talking. Only works for calls that support video.
</APIField>

### Interruption & Barge Control

Manage how the AI agent handles interruptions when users speak over it, including when to stop speaking, acknowledge interruptions, or continue regardless.

<APIField
  name="acknowledge_interruptions"
  type="boolean | number"
  default="false"
>
  Instructs the agent to acknowledge crosstalk and confirm user input when the user speaks over the agent. Can be boolean or a positive integer specifying the maximum number of interruptions to acknowledge.
</APIField>

<APIField
  name="barge_functions"
  type="boolean"
  default="true"
>
  Allow functions to be called during barging. When `false`, functions are not executed if the user is speaking.
</APIField>

<APIField
  name="barge_match_string"
  type="string"
>
  Takes a string, including a regular expression, defining barge behavior. For example, this param can direct the AI to stop when the word "hippopotomus" is input.
</APIField>

<APIField
  name="barge_min_words"
  type="integer"
>
  Defines the number of words that must be input before triggering barge behavior. Allowed values from `1`-`99`.
</APIField>

<APIField
  name="enable_barge"
  type="string"
  default='"complete,partial"'
>
  Controls when user can interrupt the AI. Valid values: `"complete"`, `"partial"`, `"all"`, or boolean. Set to `false` to disable barging.
</APIField>

<APIField
  name="interrupt_on_noise"
  type="boolean | integer"
  default="false"
>
  When enabled, barges agent upon any sound interruption longer than 1 second. Can be boolean or a positive integer specifying the threshold.
</APIField>

<APIField
  name="interrupt_prompt"
  type="string"
>
  Provide a prompt for the agent to handle crosstalk.
</APIField>

<APIField
  name="transparent_barge"
  type="boolean"
  default="true"
>
  When enabled, the AI will not respond to the user's input when the user is speaking over the agent. The agent will wait for the user to finish speaking before responding. Additionally, any attempt the LLM makes to barge will be ignored and scraped from the conversation logs.
</APIField>

<APIField
  name="transparent_barge_max_time"
  type="integer"
  default="3000"
>
  Maximum duration for transparent barge mode. Allowed values from `0`-`60,000` ms.
</APIField>

### Timeouts & Delays

Set various timing parameters that control wait times, response delays, and session limits to optimize the conversation flow and prevent dead air.

<APIField
  name="attention_timeout"
  type="integer"
  default="5000"
>
  Amount of time, in ms, to wait before prompting the user to respond. Allowed values: `0` (to disable) or `10,000`-`600,000`.
</APIField>

<APIField
  name="attention_timeout_prompt"
  type="string"
  default="The user has not responded, try to get their attention. Stay in the same language."
>
  A custom prompt that is fed into the AI when the `attention_timeout` is reached.
</APIField>

<APIField
  name="digit_timeout"
  type="integer"
  default="3000"
>
  Time, in ms, at the end of digit input to detect end of input. Allowed values from `0`-`30,000`.
</APIField>

<APIField
  name="hard_stop_prompt"
  type="string"
  default='"Explain to the user that the call has reached its maximum duration and you need to end the conversation."'
>
  A final prompt that is fed into the AI when the `hard_stop_time` is reached.
</APIField>

<APIField
  name="hard_stop_time"
  type="string"
>
  Specifies the maximum duration for the AI Agent to remain active before it exits the session. After the timeout, the AI will stop responding, and will proceed with the next SWML instruction.<br/>**Time Format**<br/><ul><li>Seconds Format: `30s`</li><li>Minutes Format: `2m`</li><li>Hours Format: `1h`</li><li>Combined Format: `1h45m30s`</li></ul>
</APIField>

<APIField
  name="inactivity_timeout"
  type="integer"
  default="600000"
>
  Amount of time, in ms, to wait before exiting the app due to inactivity. Allowed values: `0` (to disable) or `10,000`-`3,600,000`.
</APIField>

<APIField
  name="initial_sleep_ms"
  type="integer"
  default="0"
>
  Amount of time, in ms, to wait before the AI Agent starts processing. Allowed values from `0`-`300,000`.
</APIField>

<APIField
  name="outbound_attention_timeout"
  type="integer"
  default="120000"
>
  Sets a time duration for the outbound call recipient to respond to the AI agent before timeout. Allowed values from `10,000`-`600,000` ms.
</APIField>

<APIField
  name="speech_event_timeout"
  type="integer"
  default="1400"
>
  Timeout for speech events processing. Allowed values from `0`-`10,000` ms.
</APIField>

<APIField
  name="speech_timeout"
  type="integer"
  default="60000"
>
  Overall speech timeout (developer mode only). Allowed values from `0`-`600,000` ms.
</APIField>

### Audio & Media

Control background audio, hold music, and greeting messages to enhance the caller experience during different phases of the conversation.

<APIField
  name="background_file"
  type="string"
>
  URL of audio file to play in the background while AI plays in foreground.
</APIField>

<APIField
  name="background_file_loops"
  type="integer"
  default="undefined"
>
  Maximum number of times to loop playing the background file.
</APIField>

<APIField
  name="background_file_volume"
  type="integer"
  default="0"
>
  Defines `background_file` volume. Allowed values from `-50` to `50`.
</APIField>

<APIField
  name="hold_music"
  type="string"
>
  A URL for the hold music to play, accepting WAV, mp3, and [FreeSWITCH tone_stream][tone-stream].
</APIField>

<APIField
  name="hold_on_process"
  type="boolean"
  default="false"
>
  Enables hold music during SWAIG processing.
</APIField>

<APIField
  name="static_greeting"
  type="string"
>
  A static greeting to play at the start of the call.
</APIField>

<APIField
  name="static_greeting_no_barge"
  type="boolean"
  default="false"
>
  If `true`, the static greeting will not be interrupted by the user if they speak over the greeting. If `false`, the static greeting can be interrupted by the user if they speak over the greeting.
</APIField>

### SWAIG Functions

Configure SignalWire AI Gateway (SWAIG) function capabilities, including permissions, execution timing, and data persistence across function calls.

<APIField
  name="function_wait_for_talking"
  type="boolean"
  default="false"
>
  If `true`, the AI will wait for any [`filler`][functions-fillers] to finish playing before executing a function.<br/>If `false`, the AI will asynchronously execute a function while playing a filler.
</APIField>

<APIField
  name="functions_on_no_response"
  type="boolean"
  default="false"
>
  Execute functions when the user doesn't respond (on attention timeout).
</APIField>

<APIField
  name="swaig_allow_settings"
  type="boolean"
  default="true"
>
  Allows tweaking any of the indicated settings, such as barge_match_string, using the returned SWML from the SWAIG function.
</APIField>

<APIField
  name="swaig_allow_swml"
  type="boolean"
  default="true"
>
  Allows your SWAIG to return SWML to be executed.
</APIField>

<APIField
  name="swaig_post_conversation"
  type="boolean"
  default="false"
>
  Post entire conversation to any SWAIG call.
</APIField>

<APIField
  name="swaig_set_global_data"
  type="boolean"
  default="true"
>
  Allows SWAIG functions to set global data that persists across function calls.
</APIField>

### Input & DTMF

Handle dual-tone multi-frequency (DTMF) input and configure input polling for integrating external data sources during conversations.

<APIField
  name="digit_terminators"
  type="string"
>
  DTMF digit, as a string, to signal the end of input (ex: "#")
</APIField>

<APIField
  name="input_poll_freq"
  type="integer"
  default="2000"
>
  Check for input function with `check_for_input`. Allowed values from `1,000`-`10,000` ms. Example use case: Feeding an inbound SMS to AI on a voice call, eg., for collecting an email address or other complex information.
</APIField>

### Debug & Development

Enable debugging tools, logging, and performance monitoring features to help developers troubleshoot and optimize their AI agent implementations.

<APIField
  name="audible_debug"
  type="boolean"
  default="false"
>
  If `true`, the AI will announce the function that is being executed on the call.
</APIField>

<APIField
  name="audible_latency"
  type="boolean"
  default="false"
>
  Announce latency information during the call for debugging purposes.
</APIField>

<APIField
  name="cache_mode"
  type="boolean"
  default="false"
>
  Enable response caching to improve performance for repeated queries.
</APIField>

<APIField
  name="debug_webhook_level"
  type="integer"
  default="1"
>
  Enables debugging to the set URL. Allowed values from `0`-`2`. Level 0 disables, 1 provides basic info, 2 provides verbose info.
</APIField>

<APIField
  name="debug_webhook_url"
  type="string"
>
  Each interaction between the AI and end user is posted in real time to the established URL. Authentication can also be set in the url in the format of `username:password@url`.
</APIField>

<APIField
  name="enable_accounting"
  type="boolean"
  default="false"
>
  Enable usage accounting and tracking for billing and analytics purposes.
</APIField>

<APIField
  name="verbose_logs"
  type="boolean"
  default="false"
>
  Enable verbose logging (developer mode only).
</APIField>
