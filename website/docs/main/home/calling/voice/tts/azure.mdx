---
title: Azure
description: Learn how to use Azure TTS voices on the SignalWire platform.
slug: /voice/tts/azure
---

import AzureVoices from './_azure-voices.mdx';

# Microsoft Azure

Microsoft's Azure platform offers an impressive array of high-quality, multilingual voices in its Neural model.

## Languages

Azure Neural voices are interchangeably compatible with all supported languages.
Rather than setting language with the language `code`,
simply provide input text in the desired language.

Consult the Azure
[supported languages resource](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts)
for an up-to-date list of supported languages.

## Configuration {#configuration}

Azure TTS requires the following environment variables:

- `AZURE_TTS_KEY` - Your Azure Speech Services API key
- `AZURE_TTS_HOST` - Your Azure region endpoint (e.g., `eastus.api.cognitive.microsoft.com`)

Consult [Azure's authentication documentation](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-text-to-speech) for setup instructions.

## Voice ID Format {#voice-id-format}

Azure voice IDs conform to the following format:

```
azure.<voice>
```

Where `<voice>` is the full voice code from the table below (e.g., `en-US-AvaNeural`).

**Examples:**
```
azure.en-US-AvaNeural
azure.en-GB-SoniaNeural
azure.de-DE-KatjaNeural
azure.es-ES-ElviraNeural
```

**Note:** Azure voice IDs already include language information, so no additional language parameter is needed.

## Voice IDs {#voice-ids}

<div style={{"display":"inline-block","max-height":"70vh","overflow-y":"auto"}}>

<AzureVoices />

</div>

## SSML Support {#ssml}

Azure voices support [Speech Synthesis Markup Language (SSML)](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup) for advanced control over:

- Prosody (pitch, rate, volume)
- Emphasis and breaks
- Phonetic pronunciation
- Multi-language content

Consult Azure's [SSML documentation](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup) for detailed usage instructions.

---

## Examples {#examples}

Learn how to use Azure voices on the SignalWire platform.

<Tabs>
<TabItem value="swml" label="SWML">
Use the
[**`languages`**](/swml/methods/ai/languages#use-voice-strings)
SWML method to set one or more voices for an [AI agent](/swml/methods/ai).
```yaml
version: 1.0.0
sections:
  main:
  - ai:
      prompt:
        text: Have an open-ended conversation about flowers.
      languages:
        - name: English
          code: en-US
          voice: azure.en-US-AvaNeural
```
Alternatively, use the [**`say_voice`** parameter](/swml/methods/play#parameters)
of the [**`play`**](/swml/methods/play)
SWML method to select a voice for basic TTS.
```yaml
version: 1.0.0
sections:
  main:
  - set:
      say_voice: "azure.en-US-AvaNeural"
  - play: "say:Greetings. This is the Ava voice from Microsoft Azure's Neural text-to-speech model."
```
</TabItem>
<TabItem value="relay" label="RELAY Realtime SDK">
```javascript
// This example uses the Node.js SDK for SignalWire's RELAY Realtime API.
const playback = await call.playTTS({
    text: "Greetings. This is the Ava voice from Microsoft Azure's Neural text-to-speech model.",
    voice: "azure.en-US-AvaNeural",
});
await playback.ended();
```
</TabItem>
<TabItem value="cfb" label="Call Flow Builder">
Azure voices are not yet supported in Call Flow Builder.
</TabItem>
<TabItem value="cxml" label="cXML">
```xml
<?xml version="1.0" encoding="UTF-8"?>
<Response>
<Say voice="azure.en-US-AvaNeural">
    Greetings. This is the Ava voice from Microsoft Azure's Neural text-to-speech model.
</Say>
</Response>
```
</TabItem>
</Tabs>
